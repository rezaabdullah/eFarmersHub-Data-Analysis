{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eFarmersHub Data Analysis\n",
    "eFarmersHub data are stored in `gds_database` for data visualization. There are 8 tables:\n",
    "1. Income generating tables: Sale, Machine Rent & Advisory\n",
    "2. Expenditure tables: Purchase, Processing, Expense\n",
    "3. User table: This table stores all the user data\n",
    "\n",
    "The script utilizes `SQLAlchemy` as a database toolkit for CRUD operation while `Pandas` is used for data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "# data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# database toolkit\n",
    "from sqlalchemy import create_engine, MetaData, inspect, Table, Column, Integer, String, Date, Numeric, extract\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy.sql import select\n",
    "\n",
    "# read env file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# path handling\n",
    "from pathlib import Path\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "# z-score for anomaly detection\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variables\n",
    "dotenv_path = Path(\"./.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "USERNAME = os.getenv(\"USERNAME\")\n",
    "PASSWORD = os.getenv(\"PASSWORD\")\n",
    "HOST = os.getenv(\"HOST\")\n",
    "PORT = os.getenv(\"PORT\")\n",
    "DATABASE = os.getenv(\"DATABASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read Sale Table\n",
    "Sale data are stored in `gds_sale_transactions` table. For financial analysis such as revenue and profit, `net_amount` and `cogs_amount` are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sale(engine):\n",
    "    \"\"\"\n",
    "    read gds_sale_transactions table from sql database and returns df\n",
    "    :param engine: SQLAlchemy engine object\n",
    "    :return df: sale dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = \"\"\"\n",
    "                SELECT country_name, parent_name, user_type, user_region, user_name, user_id, market_type,\n",
    "                    business_category, category, product, transaction_date, transaction_id, customer_id, customer_name,\n",
    "                    customer_mobile, customer_gender, product_amount, net_amount, due_amount, cogs_amount, version,\n",
    "                    currency_exchange_rate\n",
    "                FROM (\n",
    "                    SELECT distinct user_id, country_name, user_name, user_type, parent_name, transaction_id,\n",
    "                        transaction_date, customer_id, customer_name, customer_mobile, customer_gender,\n",
    "                        market_type, sale_type, business_category, category_id, category, product_id, product,\n",
    "                        unit_type, attribute, quantity, unit_price, product_amount, sub_total_amount,\n",
    "                        commission_amount, discount_amount, net_amount, paid_amount, due_amount, due_receivable_date,\n",
    "                        version, user_join_date, user_region, customer_join_date, currency_exchange_rate, cogs_amount\n",
    "                    FROM gds_database.gds_sale_transactions\n",
    "                ) sale;\n",
    "                \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        logging.basicConfig(filename=\"./log\", filemode=\"a\", format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            level=logging.ERROR)\n",
    "        logging.error(e)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sale(df):\n",
    "    \"\"\"\n",
    "    transform sale dataframe and returns df\n",
    "    :param df: actual sale dataframe\n",
    "    :return df: transformed dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    \n",
    "    # convert date_of_transaction to datetime\n",
    "    df[\"transaction_date\"] = pd.to_datetime(df[\"transaction_date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "    # convert user_id to string\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"customer_id\"] = df[\"customer_id\"].astype(str)\n",
    "    df[\"customer_mobile\"] = df[\"customer_mobile\"].astype(str)\n",
    "    df[\"transaction_id\"] = df[\"transaction_id\"].astype(str)\n",
    "\n",
    "    # convert and round numerical columns\n",
    "    df[\"product_amount\"] = df[\"product_amount\"].astype(float)\n",
    "    df[\"net_amount\"] = df[\"net_amount\"].astype(float)\n",
    "    df[\"cogs_amount\"] = df[\"cogs_amount\"].astype(float)\n",
    "    df[\"due_amount\"] = df[\"due_amount\"].astype(float)\n",
    "    df[\"currency_exchange_rate\"] = df[\"currency_exchange_rate\"].astype(float)\n",
    "\n",
    "    # renaming columns for consistency\n",
    "    df.rename(columns={\"net_amount\" : \"revenue\"}, inplace=True)\n",
    "\n",
    "    # add transaction_category column to identify the module used for transaction\n",
    "    df[\"transaction_category\"] = \"Sale\"\n",
    "\n",
    "    # sorting data based on version and keep the latest version only\n",
    "    df = df.sort_values([\"country_name\", \"parent_name\", \"user_id\", \"transaction_id\", \"category\", \"product\",\n",
    "            \"version\"]) \\\n",
    "        .drop_duplicates(subset=[\"transaction_id\", \"category\", \"product\"], keep=\"last\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Machine Rent\n",
    "Machine Rent data are stored in `gds_machine_rent_transactions` table. For financial analysis such as revenue and profit, `net_amount` is considered.\n",
    "\n",
    "**Note:** Depreciation is not being considered at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_machine_rent(engine):\n",
    "    \"\"\"\n",
    "    read gds_machine_rent_transactions table from sql database and returns df\n",
    "    :param engine: SQLAlchemy engine object\n",
    "    :return df: sale dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = \"\"\"\n",
    "                SELECT country_name, parent_name, user_type, user_region, user_name, user_id, business_category,\n",
    "                    category, product, transaction_date, transaction_id, customer_id, customer_name,\n",
    "                    customer_mobile, customer_gender, amount, net_amount, due_amount, version, currency_exchange_rate\n",
    "                FROM (\n",
    "                    SELECT distinct user_id, country_name, user_name, user_type, parent_name, transaction_id,\n",
    "                        transaction_date, customer_id, customer_name, customer_mobile, customer_gender,\n",
    "                        business_category, category_id, category, product_id, product, unit_type, quantity,\n",
    "                        unit_price, unit_count, amount, sub_total_amount, net_amount, paid_amount, due_amount,\n",
    "                        due_receivable_date, land_type, land_size, start_date_time, end_date_time, rent_hour,\n",
    "                        version, user_join_date, user_region, customer_join_date, currency_exchange_rate\n",
    "                    FROM gds_database.gds_machine_rent_transactions\n",
    "                ) machine_rent;\n",
    "                \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        logging.basicConfig(filename=\"./log\", filemode=\"a\", format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            level=logging.ERROR)\n",
    "        logging.error(e)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_machine_rent(df):\n",
    "    \"\"\"\n",
    "    transform machine_rent dataframe and returns df\n",
    "    :param df: actual machine_rent dataframe\n",
    "    :return df: transformed dataframe\n",
    "    \"\"\"\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "    # convert date_of_transaction to datetime\n",
    "    df[\"transaction_date\"] = pd.to_datetime(df[\"transaction_date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "    # convert user_id to string\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"customer_id\"] = df[\"customer_id\"].astype(str)\n",
    "    df[\"customer_mobile\"] = df[\"customer_mobile\"].astype(str)\n",
    "    df[\"transaction_id\"] = df[\"transaction_id\"].astype(str)\n",
    "\n",
    "    # convert and round numerical columns\n",
    "    df[\"amount\"] = df[\"amount\"].astype(float)\n",
    "    df[\"net_amount\"] = df[\"net_amount\"].astype(float)\n",
    "    df[\"due_amount\"] = df[\"due_amount\"].astype(float)\n",
    "    df[\"currency_exchange_rate\"] = df[\"currency_exchange_rate\"].astype(float)\n",
    "    \n",
    "    # renaming columns for consistency\n",
    "    df.rename(columns={\"net_amount\" : \"revenue\",\n",
    "        \"amount\": \"product_amount\"}, inplace=True)\n",
    "\n",
    "    # add market_type column\n",
    "    df[\"market_type\"] = \"Farmer\"\n",
    "    df[\"transaction_category\"] = \"Machinery Rental\"\n",
    "\n",
    "    # sorting data based on version and keep the latest version only\n",
    "    df = df.sort_values([\"country_name\", \"parent_name\", \"user_id\", \"transaction_id\", \"category\", \"product\",\n",
    "            \"version\"]) \\\n",
    "        .drop_duplicates(subset=[\"transaction_id\", \"category\", \"product\"], keep=\"last\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Advisory Service\n",
    "Advisory data are stored in `gds_advisory_transactions` table. For financial analysis such as revenue and profit, `amount` is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_advisory(engine):\n",
    "    \"\"\"\n",
    "    read advisory table from sql database and returns df\n",
    "    :param engine: SQLAlchemy engine object\n",
    "    :return df: sale dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = \"\"\"\n",
    "                SELECT country_name, parent_name, user_type, user_region, user_name, user_id, business_categories,\n",
    "                    categories, transaction_date, transaction_id, customer_id, customer_name, customer_mobile,\n",
    "                        customer_gender, amount, version, currency_exchange_rate\n",
    "                FROM (\n",
    "                    SELECT distinct user_id, country_name, user_name, user_type, user_join_date, user_region,\n",
    "                        parent_name, transaction_id, transaction_date, customer_id, customer_name, customer_mobile,\n",
    "                        customer_gender, customer_join_date, categories_ids, business_categories, categories,\n",
    "                        tags_ids, tags, comments, amount, usd_amount, version, currency_exchange_rate\n",
    "                    FROM gds_database.gds_advisory_transactions\n",
    "                ) advisory;\n",
    "                \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        logging.basicConfig(filename=\"./log\", filemode=\"a\", format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            level=logging.ERROR)\n",
    "        logging.error(e)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_advisory(df):\n",
    "    \"\"\"\n",
    "    transform advisory dataframe and returns df\n",
    "    :param df: actual machine_rent dataframe\n",
    "    :return df: transformed dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "\n",
    "    # convert date_of_transaction to datetime\n",
    "    df[\"transaction_date\"] = pd.to_datetime(df[\"transaction_date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "    # convert user_id to string\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"customer_id\"] = df[\"customer_id\"].astype(str)\n",
    "    df[\"customer_mobile\"] = df[\"customer_mobile\"].astype(str)\n",
    "    df[\"transaction_id\"] = df[\"transaction_id\"].astype(str)\n",
    "\n",
    "    # convert and round numerical columns\n",
    "    df[\"amount\"] = df[\"amount\"].astype(float)\n",
    "    df[\"currency_exchange_rate\"] = df[\"currency_exchange_rate\"].astype(float)\n",
    "    \n",
    "    # renaming columns for consistency\n",
    "    df.rename(columns={\"amount\" : \"revenue\"}, inplace=True)\n",
    "\n",
    "    # add market_type column\n",
    "    df[\"market_type\"] = \"Farmer\"\n",
    "    df[\"transaction_category\"] = \"Advisory\"\n",
    "    df[\"business_category\"] = \"Advisory\"\n",
    "    df[\"category\"] = \"Advisory\"\n",
    "\n",
    "    # sorting data based on version and keep the latest version only\n",
    "    df = df.sort_values([\"country_name\", \"parent_name\", \"user_id\", \"transaction_id\", \"category\",\n",
    "        \"version\"]) \\\n",
    "        .drop_duplicates(subset=[\"transaction_id\", \"category\"], keep=\"last\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Purchase\n",
    "Purchase data are stored in `gds_purchase_transactions` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_purchase(engine):\n",
    "    \"\"\"\n",
    "    read purchase table from sql database and returns df\n",
    "    :param engine: SQLAlchemy engine object\n",
    "    :return df: sale dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = \"\"\"\n",
    "                SELECT country_name, parent_name, user_type, user_region, user_name, user_id, market_type,\n",
    "                    business_category, category, product, transaction_date, transaction_id, supplier_id, supplier_name,\n",
    "                    supplier_mobile, supplier_gender, product_amount, net_amount, due_amount, version,\n",
    "                    currency_exchange_rate\n",
    "                FROM (\n",
    "                    SELECT distinct user_id, country_name, user_name, user_type, parent_name, transaction_id,\n",
    "                        transaction_date, supplier_id, supplier_name, supplier_mobile, supplier_gender, market_type,\n",
    "                        business_category, category_id, category, product_id, product, unit_type, attribute, quantity,\n",
    "                        unit_price, product_amount, sub_total_amount, commission_amount, net_amount, paid_amount,\n",
    "                        due_amount, due_payable_date, version, user_join_date, user_region, supplier_join_date,\n",
    "                        currency_exchange_rate\n",
    "                    FROM gds_database.gds_purchase_transactions\n",
    "                ) purchase;\n",
    "                \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        logging.basicConfig(filename=\"./log\", filemode=\"a\", format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.ERROR)\n",
    "        logging.error(e)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_purchase(df):\n",
    "    \"\"\"\n",
    "    transform purchase dataframe and returns df\n",
    "    :param df: actual purchase dataframe\n",
    "    :return df: transformed dataframe\n",
    "    \"\"\"\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    \n",
    "    # convert transaction_date to datetime\n",
    "    df[\"transaction_date\"] = pd.to_datetime(df[\"transaction_date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "    # convert user_id to string\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"supplier_id\"] = df[\"supplier_id\"].astype(str)\n",
    "    df[\"supplier_mobile\"] = df[\"supplier_mobile\"].astype(str)\n",
    "    df[\"transaction_id\"] = df[\"transaction_id\"].astype(str)\n",
    "\n",
    "    # convert and round numerical columns\n",
    "    df[\"net_amount\"] = df[\"net_amount\"].astype(float)\n",
    "    df[\"due_amount\"] = df[\"due_amount\"].astype(float)   \n",
    "    df[\"currency_exchange_rate\"] = df[\"currency_exchange_rate\"].astype(float)\n",
    "\n",
    "    # renaming columns for consistency\n",
    "    df.rename(columns={\"net_amount\" : \"expenditure\",\n",
    "        \"product_amount\" : \"product_expenditure\"}, inplace=True)\n",
    "\n",
    "    # add market_type column\n",
    "    df[\"transaction_category\"] = \"Purchase\"\n",
    "\n",
    "    # sorting data based on version and keep the latest version only\n",
    "    df = df.sort_values([\"country_name\", \"parent_name\", \"user_id\", \"transaction_id\", \"category\", \"product\",\n",
    "            \"version\"]) \\\n",
    "        .drop_duplicates(subset=[\"transaction_id\", \"category\", \"product\"], keep=\"last\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Processing\n",
    "Processing data are stored in `gds_processing_transactions` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_processing(engine):\n",
    "    \"\"\"\n",
    "    read processing table from sql database and returns df\n",
    "    :param engine: SQLAlchemy engine object\n",
    "    :return df: sale dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = \"\"\"\n",
    "                SELECT country_name, parent_name, user_type, user_region, user_name, user_id, business_category,\n",
    "                    category, product, transaction_date, transaction_id, amount, production_cost, version,\n",
    "                    currency_exchange_rate\n",
    "                FROM (\n",
    "                    SELECT distinct user_id, country_name, user_name, user_type, parent_name, transaction_id,\n",
    "                        transaction_date, business_category, category_id, category, product_id, product, unit_type,\n",
    "                        quantity, unit_price, amount, production_cost, version, user_join_date, user_region,\n",
    "                        currency_exchange_rate\n",
    "                    FROM gds_database.gds_processing_transactions\n",
    "                ) processing;\n",
    "                \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        logging.basicConfig(filename=\"./log\", filemode=\"a\", format=\"%(asctime)s - %(levelname)s - %(message)s\", level=logging.ERROR)\n",
    "        logging.error(e)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_processing(df):\n",
    "    \"\"\"\n",
    "    transform processing dataframe and returns df\n",
    "    :param df: actual processing dataframe\n",
    "    :return df: transformed dataframe\n",
    "    \"\"\"\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    \n",
    "    # convert transaction_date to datetime\n",
    "    df[\"transaction_date\"] = pd.to_datetime(df[\"transaction_date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "    # convert user_id to string\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"transaction_id\"] = df[\"transaction_id\"].astype(str)\n",
    "\n",
    "    # convert and round numerical columns\n",
    "    df[\"amount\"] = df[\"amount\"].astype(float)\n",
    "    df[\"production_cost\"] = df[\"production_cost\"].astype(float)\n",
    "    df[\"currency_exchange_rate\"] = df[\"currency_exchange_rate\"].astype(float)\n",
    "\n",
    "    # renaming columns for consistency\n",
    "    df.rename(columns={\"production_cost\" : \"expenditure\",\n",
    "        \"amount\" : \"product_expenditure\"}, inplace=True)\n",
    "\n",
    "    # add transaction category column\n",
    "    df[\"market_type\"] = df[\"user_type\"]\n",
    "    df[\"transaction_category\"] = \"Processing\"\n",
    "\n",
    "    # sorting data based on version and keep the latest version only\n",
    "    df = df.sort_values([\"country_name\", \"parent_name\", \"user_id\", \"transaction_id\", \"category\", \"product\",\n",
    "            \"version\"]) \\\n",
    "        .drop_duplicates(subset=[\"transaction_id\", \"category\", \"product\"], keep=\"last\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Machine Purchase\n",
    "Machine Purchase data are stored in `gds_machine_purchase_transactions` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_machine_purchase(engine):\n",
    "    \"\"\"\n",
    "    read machine_purchase table from sql database and returns df\n",
    "    :param engine: SQLAlchemy engine object\n",
    "    :return df: sale dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = \"\"\"\n",
    "                SELECT country_name, parent_name, user_type, user_region, user_name, user_id, business_category,\n",
    "                    category, product, transaction_date, transaction_id, supplier_id, supplier_name,\n",
    "                    supplier_mobile, supplier_gender, total_amount, due_amount, version,\n",
    "                    currency_exchange_rate\n",
    "                FROM (\n",
    "                    SELECT distinct user_id, country_name, user_name, user_type, parent_name, transaction_id,\n",
    "                        transaction_date, supplier_id, supplier_name, supplier_mobile, supplier_gender,\n",
    "                        business_category, category_id, category, product_id, product, quantity, unit_price,\n",
    "                        total_amount, paid_amount, due_amount, due_payable_date, version, user_join_date, user_region,\n",
    "                        supplier_join_date, currency_exchange_rate\n",
    "                    FROM gds_database.gds_machine_purchase_transactions\n",
    "                ) machine_purchase;\n",
    "                \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        logging.basicConfig(filename=\"./log\", filemode=\"a\", format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            level=logging.ERROR)\n",
    "        logging.error(e)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_machine_purchase(df):\n",
    "    \"\"\"\n",
    "    transform machine_purchase dataframe and returns df\n",
    "    :param df: actual machine_purchase dataframe\n",
    "    :return df: transformed dataframe\n",
    "    \"\"\"\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    \n",
    "    # convert transaction_date to datetime\n",
    "    df[\"transaction_date\"] = pd.to_datetime(df[\"transaction_date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "    # convert user_id to string\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"supplier_id\"] = df[\"supplier_id\"].astype(str)\n",
    "    df[\"supplier_mobile\"] = df[\"supplier_mobile\"].astype(str)\n",
    "    df[\"transaction_id\"] = df[\"transaction_id\"].astype(str)\n",
    "\n",
    "    # convert and round numerical columns\n",
    "    df[\"total_amount\"] = df[\"total_amount\"].astype(float)\n",
    "    df[\"due_amount\"] = df[\"due_amount\"].astype(float)\n",
    "    df[\"currency_exchange_rate\"] = df[\"currency_exchange_rate\"].astype(float)    \n",
    "\n",
    "    # usd conversion\n",
    "    df.rename(columns={\"total_amount\" : \"expenditure\"}, inplace=True)\n",
    "\n",
    "    # add transaction category column\n",
    "    df[\"market_type\"] = df[\"user_type\"]\n",
    "    df[\"transaction_category\"] = \"Machinery Purchase\"\n",
    "\n",
    "    # sorting data based on version and keep the latest version only\n",
    "    df = df.sort_values([\"country_name\", \"parent_name\", \"user_id\", \"transaction_id\", \"category\", \"product\",\n",
    "            \"version\"]) \\\n",
    "        .drop_duplicates(subset=[\"transaction_id\"], keep=\"last\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Expense\n",
    "Expense data are stored in `gds_expense_transactions` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_expense(engine):\n",
    "    \"\"\"\n",
    "    read expense table from sql database and returns df\n",
    "    :param engine: SQLAlchemy engine object\n",
    "    :return df: sale dataframe\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            query = \"\"\"\n",
    "                SELECT country_name, parent_name, user_type, user_region, user_name, user_id, expense_category,\n",
    "                    business_category, product_category, expense_type, transaction_date, transaction_id, total_amount,\n",
    "                    version, currency_exchange_rate\n",
    "                FROM (\n",
    "                    SELECT distinct user_id, country_name, user_name, user_type, parent_name, transaction_id,\n",
    "                        transaction_date, expense_category, expense_type, total_amount, business_category,\n",
    "                        product_category_id, product_category, version, user_join_date, user_region,\n",
    "                        currency_exchange_rate\n",
    "                    FROM gds_database.gds_expense_transactions\n",
    "                ) expense;\n",
    "                \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "    except Exception as e:\n",
    "        logging.basicConfig(filename=\"./log\", filemode=\"a\", format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "            level=logging.ERROR)\n",
    "        logging.error(e)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_expense(df):\n",
    "    \"\"\"\n",
    "    transform expense dataframe and returns df\n",
    "    :param df: actual expense dataframe\n",
    "    :return df: transformed dataframe\n",
    "    \"\"\"\n",
    "    # drop duplicates\n",
    "    df.drop_duplicates(inplace=True, ignore_index=True)\n",
    "    \n",
    "    # convert transaction_date to datetime\n",
    "    df[\"transaction_date\"] = pd.to_datetime(df[\"transaction_date\"], format=\"%Y/%m/%d\")\n",
    "\n",
    "    # convert user_id to string\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(str)\n",
    "    df[\"transaction_id\"] = df[\"transaction_id\"].astype(str)\n",
    "\n",
    "    # convert and round numerical columns\n",
    "    df[\"total_amount\"] = df[\"total_amount\"].astype(float)\n",
    "    df[\"currency_exchange_rate\"] = df[\"currency_exchange_rate\"].astype(float)\n",
    "\n",
    "    # revenue & profit\n",
    "    df.rename(columns={\"total_amount\" : \"expenditure\",\n",
    "        \"product_category\" : \"category\"}, inplace=True)\n",
    "\n",
    "    # add transaction category column\n",
    "    df[\"market_type\"] = df[\"user_type\"]\n",
    "    df[\"transaction_category\"] = \"Expense\"\n",
    "\n",
    "    # sorting data based on version and keep the latest version only\n",
    "    df = df.sort_values([\"country_name\", \"parent_name\", \"user_id\", \"transaction_id\", \"expense_category\",\n",
    "            \"category\", \"expense_type\", \"version\"]) \\\n",
    "        .drop_duplicates(subset=[\"transaction_id\", \"expense_category\", \"category\", \"expense_type\"],\n",
    "            keep=\"last\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_income(df):\n",
    "    \"\"\"\n",
    "    identify data anomaly especially net_amount\n",
    "    :param df: transaction dataframe\n",
    "    :return df: filtered df\n",
    "    \"\"\"\n",
    "    agg_df = df.groupby([\"transaction_category\", \"user_name\", \"user_id\", \"transaction_id\"]) \\\n",
    "        .agg(total_revenue=(\"revenue\", \"sum\")).reset_index()\n",
    "    agg_df[\"z_score\"] = agg_df.groupby([\"user_id\", \"transaction_category\"])[\"total_revenue\"] \\\n",
    "        .transform(lambda x : zscore(x, ddof=1))\n",
    "    anomaly = agg_df.loc[abs(agg_df[\"z_score\"]) > 3]\n",
    "    transaction_id_list = anomaly[\"transaction_id\"].tolist()\n",
    "    mask = df[\"transaction_id\"].isin(transaction_id_list)\n",
    "    df = df[~mask]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_expenditure(df):\n",
    "    \"\"\"\n",
    "    identify data anomaly especially net_amount\n",
    "    :param df: transaction dataframe\n",
    "    :return df: filtered df\n",
    "    \"\"\"\n",
    "    agg_df = df.groupby([\"transaction_category\", \"user_name\", \"user_id\", \"transaction_id\"]) \\\n",
    "        .agg(total_expenditure=(\"expenditure\", \"sum\")).reset_index()\n",
    "    agg_df[\"z_score\"] = agg_df.groupby([\"user_id\", \"transaction_category\"])[\"total_expenditure\"] \\\n",
    "        .transform(lambda x : zscore(x, ddof=1))\n",
    "    anomaly = agg_df.loc[abs(agg_df[\"z_score\"]) > 3]\n",
    "    transaction_id_list = anomaly[\"transaction_id\"].tolist()\n",
    "    mask = df[\"transaction_id\"].isin(transaction_id_list)\n",
    "    df = df[~mask]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # initiate connection to database\n",
    "    connect_url = URL.create(\n",
    "        \"mysql+pymysql\",\n",
    "        username=USERNAME,\n",
    "        password=PASSWORD,\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        database=DATABASE\n",
    "    )\n",
    "    engine = create_engine(connect_url)\n",
    "\n",
    "    # debug\n",
    "    # with engine.connect() as conn:\n",
    "    #     inspector = inspect(engine)\n",
    "    #     table_names = inspector.get_table_names()\n",
    "    #     print(table_names)\n",
    "\n",
    "    # sale\n",
    "    sale = extract_sale(engine)\n",
    "    sale = transform_sale(sale)\n",
    "    # sale.to_csv(\"../output/sale.csv\", index=False)\n",
    "\n",
    "    # machine rent\n",
    "    machine_rent = extract_machine_rent(engine)\n",
    "    machine_rent = transform_machine_rent(machine_rent)\n",
    "    # machine_rent.to_csv(\"../output/machine_rent.csv\", index=False)\n",
    "\n",
    "    # advisory\n",
    "    advisory = extract_advisory(engine)\n",
    "    advisory = transform_advisory(advisory)\n",
    "    # advisory.to_csv(\"../output/advisory.csv\", index=False)\n",
    "\n",
    "    # purchase\n",
    "    purchase = extract_purchase(engine)\n",
    "    purchase = transform_purchase(purchase)\n",
    "    # purchase.to_csv(\"../output/purchase.csv\", index=False)\n",
    "\n",
    "    # processing\n",
    "    processing = extract_processing(engine)\n",
    "    processing = transform_processing(processing)\n",
    "    # processing.to_csv(\"../output/processing.csv\", index=False)\n",
    "\n",
    "    # machine purchase\n",
    "    machine_purchase = extract_machine_purchase(engine)\n",
    "    machine_purchase = transform_machine_purchase(machine_purchase)\n",
    "    # machine_purchase.to_csv(\"../output/machine_purchase.csv\", index=False)\n",
    "\n",
    "    # expense\n",
    "    expense = extract_expense(engine)\n",
    "    expense = transform_expense(expense)\n",
    "    # expense.to_csv(\"../output/expense.csv\", index=False)\n",
    "\n",
    "    # concat all cash-in transactions\n",
    "    income = pd.concat([sale, machine_rent, advisory], sort=False, ignore_index=True)\n",
    "    income.to_csv(\"../output/income_actual.csv\", index=False)\n",
    "    income = anomaly_income(income)\n",
    "    # usd conversion\n",
    "    income[\"product_amount_usd\"] = round(income[\"product_amount\"] / income[\"currency_exchange_rate\"], 4)\n",
    "    income[\"revenue_usd\"] = round(income[\"revenue\"] / income[\"currency_exchange_rate\"], 4)\n",
    "    income[\"cogs_amount_usd\"] = round(income[\"cogs_amount\"] / income[\"currency_exchange_rate\"], 4)\n",
    "    # data cleaning for outliers\n",
    "    income = income.loc[(income[\"revenue_usd\"] < 10000) & (income[\"cogs_amount_usd\"] < 10000)]\n",
    "    income.to_csv(\"../output/income_filter.csv\", index=False)\n",
    "\n",
    "    # concat all cash-out transactions\n",
    "    expenditure = pd.concat([purchase, machine_purchase, processing], sort=False, ignore_index=True)\n",
    "    expenditure.to_csv(\"../output/expenditure_actual.csv\", index=False)\n",
    "    expenditure = anomaly_expenditure(expenditure)\n",
    "    # usd conversion\n",
    "    expenditure[\"product_expenditure_usd\"] = round(expenditure[\"product_expenditure\"] / \n",
    "        expenditure[\"currency_exchange_rate\"], 4)\n",
    "    expenditure[\"expenditure_usd\"] = round(expenditure[\"expenditure\"] / expenditure[\"currency_exchange_rate\"], 4)\n",
    "    expenditure.to_csv(\"../output/expenditure_filter.csv\", index=False)\n",
    "    # data cleaning for outliers\n",
    "    expenditure = expenditure.loc[expenditure[\"expenditure_usd\"] < 10000]\n",
    "    expenditure.to_csv(\"../output/expenditure_filter.csv\", index=False)\n",
    "\n",
    "    # filter direct cost\n",
    "    direct_cost = expense.loc[expense[\"expense_category\"] == \"Direct Cost\"]\n",
    "    direct_cost.to_csv(\"../output/direct_cost_actual.csv\", index=False)\n",
    "    direct_cost = anomaly_expenditure(direct_cost)\n",
    "    # usd conversion\n",
    "    direct_cost[\"direct_cost_usd\"] = round(direct_cost[\"expenditure\"] / direct_cost[\"currency_exchange_rate\"], 4)\n",
    "    # data cleaning for outliers\n",
    "    direct_cost = direct_cost.loc[direct_cost[\"direct_cost_usd\"] < 10000]\n",
    "    direct_cost.to_csv(\"../output/direct_cost_filter.csv\", index=False)\n",
    "\n",
    "    # filter indirect cost\n",
    "    indirect_cost = expense.loc[expense[\"expense_category\"] == \"Indirect Cost\"]\n",
    "    indirect_cost.to_csv(\"../output/indirect_cost_actual.csv\", index=False)\n",
    "    indirect_cost = anomaly_expenditure(indirect_cost)\n",
    "    # usd conversion\n",
    "    indirect_cost[\"indirect_cost_usd\"] = round(indirect_cost[\"expenditure\"] / indirect_cost[\"currency_exchange_rate\"], 4)\n",
    "    # data cleaning for outliers\n",
    "    indirect_cost = indirect_cost.loc[indirect_cost[\"indirect_cost_usd\"] < 10000]\n",
    "    indirect_cost.to_csv(\"../output/indirect_cost_filter.csv\", index=False)\n",
    "    expense = pd.concat([direct_cost, indirect_cost], sort=False, ignore_index=True)\n",
    "    expense.drop(columns=[\"expense_type\"], inplace=True)\n",
    "\n",
    "    master_data = pd.concat([income, expenditure, expense], sort=False, ignore_index=True)\n",
    "    master_data.drop(columns=[\"business_categories\", \"categories\"], inplace=True)\n",
    "    master_data.to_csv(\"../output/master_data.csv\", index=False)\n",
    "    master_data.to_sql(\"master_data_global\", con=engine, if_exists='replace', index = False)\n",
    "\n",
    "    # # cumulative revenue & profit\n",
    "    # cash_flow = income.groupby([\"country_name\", \"user_type\", \"parent_name\", \"user_region\", \"user_name\",\n",
    "    #     \"transaction_date\"]) \\\n",
    "    #     .agg(unique_income_transaction=(\"transaction_id\", \"nunique\"),\n",
    "    #         revenue=(\"revenue\", \"sum\"),\n",
    "    #         currency_exchange_rate=(\"currency_exchange_rate\", \"mean\"),\n",
    "    #         total_cogs=(\"cogs_amount\", \"sum\")).reset_index()\n",
    "    \n",
    "    # # filter direct cost\n",
    "    # direct_cost = expense.loc[expense[\"expense_category\"] == \"Direct Cost\"]\n",
    "    # direct_cost = direct_cost.groupby([\"country_name\", \"user_type\", \"parent_name\", \"user_region\", \"user_name\",\n",
    "    #     \"transaction_date\"]) \\\n",
    "    #     .agg(total_direct_cost=(\"expenditure\", \"sum\")).reset_index()\n",
    "\n",
    "    # # filter indirect cost\n",
    "    # indirect_cost = expense.loc[expense[\"expense_category\"] == \"Indirect Cost\"]\n",
    "    # indirect_cost = indirect_cost.groupby([\"country_name\", \"user_type\", \"parent_name\", \"user_region\", \"user_name\",\n",
    "    #     \"transaction_date\"]) \\\n",
    "    #     .agg(total_indirect_cost=(\"expenditure\", \"sum\")).reset_index()\n",
    "\n",
    "    # # expenditure\n",
    "    # expenditure = pd.concat([purchase, machine_purchase, processing], sort=False, ignore_index=True)\n",
    "\n",
    "    # # cumulative expenditure\n",
    "    # expenditure = expenditure.groupby([\"country_name\", \"user_type\", \"parent_name\", \"user_region\", \"user_name\",\n",
    "    #     \"transaction_date\"]) \\\n",
    "    #     .agg(unique_expenditure_transaction=(\"transaction_id\", \"nunique\"),\n",
    "    #         expenditure=(\"expenditure\", \"sum\")).reset_index()\n",
    "\n",
    "    # # join expenditure with revenue table\n",
    "    # cash_flow = cash_flow.merge(expenditure, how=\"outer\", on=[\"country_name\", \"user_type\", \"parent_name\",\n",
    "    #     \"user_region\", \"user_name\", \"transaction_date\"])\n",
    "\n",
    "    # # join expenditure with revenue table\n",
    "    # cash_flow = cash_flow.merge(direct_cost, how=\"outer\", on=[\"country_name\", \"user_type\",\n",
    "    #     \"parent_name\", \"user_region\", \"user_name\", \"transaction_date\"])\n",
    "\n",
    "    # cash_flow = cash_flow.merge(indirect_cost, how=\"outer\", on=[\"country_name\", \"user_type\",\n",
    "    #     \"parent_name\", \"user_region\", \"user_name\", \"transaction_date\"])\n",
    "\n",
    "    # cash_flow = cash_flow.sort_values([\"country_name\", \"parent_name\", \"user_name\",\n",
    "    #     \"transaction_date\"])\n",
    "    \n",
    "    # # usd conversion\n",
    "    # cash_flow[\"revenue_usd\"] = round(cash_flow[\"revenue\"] / cash_flow[\"currency_exchange_rate\"] , 4)\n",
    "    # cash_flow[\"cogs_usd\"] = round(cash_flow[\"total_cogs\"] / cash_flow[\"currency_exchange_rate\"] , 4)\n",
    "    # cash_flow[\"total_direct_cost_usd\"] = round(cash_flow[\"total_direct_cost\"] / cash_flow[\"currency_exchange_rate\"] , 4)\n",
    "    # cash_flow[\"total_indirect_cost_usd\"] = round(cash_flow[\"total_indirect_cost\"] / cash_flow[\"currency_exchange_rate\"] , 4)\n",
    "    # cash_flow[\"expenditure_usd\"] = round(cash_flow[\"expenditure\"] / cash_flow[\"currency_exchange_rate\"] , 4)\n",
    "\n",
    "    # # filter transactions that are more than 10000 USD\n",
    "    # cash_flow = cash_flow.loc[cash_flow[\"revenue_usd\"] < 10000]\n",
    "    # cash_flow = cash_flow.loc[cash_flow[\"total_direct_cost_usd\"] < 10000]\n",
    "    # cash_flow = cash_flow.loc[cash_flow[\"total_indirect_cost_usd\"] < 10000]\n",
    "    # cash_flow = cash_flow.loc[cash_flow[\"expenditure_usd\"] < 10000]\n",
    "\n",
    "    # cash_flow.to_sql(\"cash_flow_global\", con=engine, if_exists='replace', index = False)\n",
    "    # # cash_flow.to_sql(\"cash_flow_global\", con=engine, if_exists='replace', index = False)\n",
    "    # cash_flow.to_csv(\"../output/cash_flow.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "381d99941aa843f9feea4709de25f28f27171c4591a40a61ca7894a7d74153c2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
